{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3775e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de92944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./dataset/train.csv')\n",
    "test = pd.read_csv('./dataset/test.csv')\n",
    "sample_submission = pd.read_csv('dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c12726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>영상이나 음악이 이쁘다 해도 미화시킨 불륜일뿐</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>히치콕이 이 영화를 봤다면 분명 박수를 쳤을듯...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>괜찮은 음악영화가 또 나왔군요!!! 따뜻한 겨울이 될 것 같아요~</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>아무래도 20년도지난작품이라 지금보기는너무유치하다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>지금까지의 영화들이 그랬듯. 이 영화역시 일본에 대한 미화는 여전하다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                 document  label\n",
       "0   1                영상이나 음악이 이쁘다 해도 미화시킨 불륜일뿐      0\n",
       "1   2             히치콕이 이 영화를 봤다면 분명 박수를 쳤을듯...      1\n",
       "2   3     괜찮은 음악영화가 또 나왔군요!!! 따뜻한 겨울이 될 것 같아요~      1\n",
       "3   4              아무래도 20년도지난작품이라 지금보기는너무유치하다      0\n",
       "4   5  지금까지의 영화들이 그랬듯. 이 영화역시 일본에 대한 미화는 여전하다.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3585d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['document'] = train['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0836a78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>영상이나 음악이 이쁘다 해도 미화시킨 불륜일뿐</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>히치콕이 이 영화를 봤다면 분명 박수를 쳤을듯</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>괜찮은 음악영화가 또 나왔군요 따뜻한 겨울이 될 것 같아요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>아무래도 년도지난작품이라 지금보기는너무유치하다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>지금까지의 영화들이 그랬듯 이 영화역시 일본에 대한 미화는 여전하다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                               document  label\n",
       "0   1              영상이나 음악이 이쁘다 해도 미화시킨 불륜일뿐      0\n",
       "1   2              히치콕이 이 영화를 봤다면 분명 박수를 쳤을듯      1\n",
       "2   3       괜찮은 음악영화가 또 나왔군요 따뜻한 겨울이 될 것 같아요      1\n",
       "3   4              아무래도 년도지난작품이라 지금보기는너무유치하다      0\n",
       "4   5  지금까지의 영화들이 그랬듯 이 영화역시 일본에 대한 미화는 여전하다      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c514ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['document'] = test['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e0d8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>시간 때우기 좋은 영화 지루함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>훈훈한 정이 느껴지는 영화 가족끼리 드라마 보듯이 보면 딱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>멋있는 영화입니다 잊을 수 없는</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>너무 감동적이네요 펑펑 울었습니다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                          document\n",
       "0   1                  시간 때우기 좋은 영화 지루함\n",
       "1   2  훈훈한 정이 느껴지는 영화 가족끼리 드라마 보듯이 보면 딱\n",
       "2   3                                  \n",
       "3   4                 멋있는 영화입니다 잊을 수 없는\n",
       "4   5                너무 감동적이네요 펑펑 울었습니다"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb4fd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features: 100, Accuracy: 0.715\n",
      "max_features: 200, Accuracy: 0.749\n",
      "max_features: 300, Accuracy: 0.785\n",
      "max_features: 400, Accuracy: 0.801\n",
      "max_features: 500, Accuracy: 0.81\n",
      "max_features: 600, Accuracy: 0.822\n",
      "max_features: 700, Accuracy: 0.84\n",
      "max_features: 800, Accuracy: 0.833\n",
      "max_features: 900, Accuracy: 0.836\n",
      "max_features: 1000, Accuracy: 0.844\n",
      "max_features: 1100, Accuracy: 0.85\n",
      "max_features: 1200, Accuracy: 0.848\n",
      "max_features: 1300, Accuracy: 0.852\n",
      "max_features: 1400, Accuracy: 0.852\n",
      "max_features: 1500, Accuracy: 0.849\n",
      "max_features: 1600, Accuracy: 0.859\n",
      "max_features: 1700, Accuracy: 0.86\n",
      "max_features: 1800, Accuracy: 0.859\n",
      "max_features: 1900, Accuracy: 0.859\n",
      "max_features: 2000, Accuracy: 0.86\n",
      "max_features: 2100, Accuracy: 0.858\n",
      "max_features: 2200, Accuracy: 0.859\n",
      "max_features: 2300, Accuracy: 0.865\n",
      "max_features: 2400, Accuracy: 0.867\n",
      "max_features: 2500, Accuracy: 0.865\n",
      "max_features: 2600, Accuracy: 0.863\n",
      "max_features: 2700, Accuracy: 0.859\n",
      "max_features: 2800, Accuracy: 0.862\n",
      "max_features: 2900, Accuracy: 0.861\n",
      "max_features: 3000, Accuracy: 0.859\n",
      "max_features: 3100, Accuracy: 0.861\n",
      "max_features: 3200, Accuracy: 0.862\n",
      "max_features: 3300, Accuracy: 0.865\n",
      "max_features: 3400, Accuracy: 0.868\n",
      "max_features: 3500, Accuracy: 0.869\n",
      "max_features: 3600, Accuracy: 0.868\n",
      "max_features: 3700, Accuracy: 0.867\n",
      "max_features: 3800, Accuracy: 0.868\n",
      "max_features: 3900, Accuracy: 0.868\n",
      "max_features: 4000, Accuracy: 0.866\n",
      "max_features: 4100, Accuracy: 0.866\n",
      "max_features: 4200, Accuracy: 0.867\n",
      "max_features: 4300, Accuracy: 0.867\n",
      "max_features: 4400, Accuracy: 0.87\n",
      "max_features: 4500, Accuracy: 0.87\n",
      "max_features: 4600, Accuracy: 0.872\n",
      "max_features: 4700, Accuracy: 0.872\n",
      "max_features: 4800, Accuracy: 0.871\n",
      "max_features: 4900, Accuracy: 0.872\n",
      "max_features: 5000, Accuracy: 0.873\n",
      "max_features: 5100, Accuracy: 0.875\n",
      "max_features: 5200, Accuracy: 0.874\n",
      "max_features: 5300, Accuracy: 0.872\n",
      "max_features: 5400, Accuracy: 0.874\n",
      "max_features: 5500, Accuracy: 0.873\n",
      "max_features: 5600, Accuracy: 0.872\n",
      "max_features: 5700, Accuracy: 0.874\n",
      "max_features: 5800, Accuracy: 0.871\n",
      "max_features: 5900, Accuracy: 0.871\n",
      "max_features: 6000, Accuracy: 0.871\n",
      "max_features: 6100, Accuracy: 0.871\n",
      "max_features: 6200, Accuracy: 0.871\n",
      "max_features: 6300, Accuracy: 0.871\n",
      "max_features: 6400, Accuracy: 0.87\n",
      "max_features: 6500, Accuracy: 0.871\n",
      "max_features: 6600, Accuracy: 0.871\n",
      "max_features: 6700, Accuracy: 0.87\n",
      "max_features: 6800, Accuracy: 0.87\n",
      "max_features: 6900, Accuracy: 0.873\n",
      "max_features: 7000, Accuracy: 0.874\n",
      "max_features: 7100, Accuracy: 0.874\n",
      "max_features: 7200, Accuracy: 0.876\n",
      "max_features: 7300, Accuracy: 0.876\n",
      "max_features: 7400, Accuracy: 0.876\n",
      "max_features: 7500, Accuracy: 0.876\n",
      "max_features: 7600, Accuracy: 0.877\n",
      "max_features: 7700, Accuracy: 0.877\n",
      "max_features: 7800, Accuracy: 0.877\n",
      "max_features: 7900, Accuracy: 0.877\n",
      "max_features: 8000, Accuracy: 0.875\n",
      "max_features: 8100, Accuracy: 0.875\n",
      "max_features: 8200, Accuracy: 0.875\n",
      "max_features: 8300, Accuracy: 0.875\n",
      "max_features: 8400, Accuracy: 0.876\n",
      "max_features: 8500, Accuracy: 0.876\n",
      "max_features: 8600, Accuracy: 0.876\n",
      "max_features: 8700, Accuracy: 0.876\n",
      "max_features: 8800, Accuracy: 0.876\n",
      "max_features: 8900, Accuracy: 0.878\n",
      "max_features: 9000, Accuracy: 0.878\n",
      "max_features: 9100, Accuracy: 0.878\n",
      "max_features: 9200, Accuracy: 0.879\n",
      "max_features: 9300, Accuracy: 0.878\n",
      "max_features: 9400, Accuracy: 0.878\n",
      "max_features: 9500, Accuracy: 0.878\n",
      "max_features: 9600, Accuracy: 0.879\n",
      "max_features: 9700, Accuracy: 0.88\n",
      "max_features: 9800, Accuracy: 0.88\n",
      "max_features: 9900, Accuracy: 0.881\n"
     ]
    }
   ],
   "source": [
    "# tf-idf 벡터화\n",
    "for max_features in range(100, 10000, 100):\n",
    "    vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1, 3), max_features=max_features)\n",
    "    \n",
    "    X = train['document']\n",
    "    y = np.array(train.label)\n",
    "    \n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "    \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_eval = vectorizer.transform(X_eval)\n",
    "    lgs = LogisticRegression(class_weight='balanced')\n",
    "    lgs.fit(X_train, y_train)\n",
    "    predicted = lgs.predict(X_eval)\n",
    "    print(f\"max_features: {max_features}, Accuracy: {lgs.score(X_eval, y_eval)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "912ee647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  9900일 때 가장 큰 정확도 0.881 를 얻었습니다.\n",
    "vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3), max_features=5100)\n",
    "\n",
    "X = train['document']\n",
    "y = np.array(train.label)\n",
    "\n",
    "# 벡터화\n",
    "X_train = vectorizer.fit_transform(X)\n",
    "X_test = vectorizer.transform(test['document'])\n",
    "\n",
    "# 로지스틱 회귀\n",
    "lgs = LogisticRegression(class_weight='balanced')\n",
    "lgs.fit(X_train, y)\n",
    "predicted = lgs.predict(X_test)\n",
    "\n",
    "# 왜 똑같은 걸 두번..? \n",
    "X_train = vectorizer.fit_transform(train['document'])\n",
    "X_test = vectorizer.transform(test['document'])\n",
    "y = np.array(train.label)\n",
    "\n",
    "lgs = LogisticRegression(class_weight='balanced')\n",
    "lgs.fit(X_train, y)\n",
    "predicted = lgs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd616f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('dataset/sample_submission.csv')\n",
    "sample_submission.loc[:, 'label'] = predicted\n",
    "\n",
    "sample_submission.to_csv('sample_submission_day2_logistic3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed9921d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fe3fcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading tensorflow-2.7.0-cp38-cp38-win_amd64.whl (430.8 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\itshony\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\itshony\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.13.3)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\itshony\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (4.0.1)\n",
      "Collecting flatbuffers<3.0,>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "Collecting gast<0.5.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting keras<2.8,>=2.7.0rc0\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-2-py2.py3-none-win_amd64.whl (13.0 MB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\itshony\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow) (1.22.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.6.0-cp38-cp38-win_amd64.whl (2.8 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.43.0-cp38-cp38-win_amd64.whl (3.4 MB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.3-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\itshony\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorflow) (0.37.1)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\itshony\\anaconda3\\envs\\nlp\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (58.0.4)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.10.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\itshony\\anaconda3\\envs\\nlp\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\itshony\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.10-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=918309e6efc6c1c8c15e8753f9e0ddfc7bf0d809498c873fa4ccd2484a3cacb7\n",
      "  Stored in directory: c:\\users\\itshony\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-4.2.4 charset-normalizer-2.0.10 flatbuffers-2.0 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.43.0 h5py-3.6.0 idna-3.3 importlib-metadata-4.10.1 keras-2.7.0 keras-preprocessing-1.1.2 libclang-12.0.0 markdown-3.3.6 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.27.1 requests-oauthlib-1.3.0 rsa-4.8 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.23.1 termcolor-1.1.0 urllib3-1.26.8 werkzeug-2.0.2\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e98fff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
